{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Espectrograma para la Detección de Aves: Documentación del Proyecto\n",
    "\n",
    "## Documentación\n",
    "\n",
    "El archivo **`Bird_Recognition_Prosperina_Generate_Spectograms`** se enmarca en un proyecto de investigación académica centrado en la detección de aves a partir de sus vocalizaciones. El objetivo principal de este archivo es la generación de espectrogramas o imágenes de los audios de aves, los cuales se encuentran segmentados en tramos de 2 segundos. Estos datos se ubican en la carpeta **`Bird-Audio-Classification-Prosperina\\Dataset-Birds\\training`**.\n",
    "\n",
    "## Herramientas y Bibliotecas Utilizadas\n",
    "\n",
    "- **`Python`**: Lenguaje de programación principal utilizado en el proyecto.\n",
    "- **`Librerías de Procesamiento de Señales de Audio`**:\n",
    "  - **`Librosa`**: Utilizada para cargar y visualizar espectrogramas de audio.\n",
    "  - **`Noisereduce`**: Empleada para reducir el ruido de las grabaciones de audio.\n",
    "- **`Librerías de Aprendizaje Automático`**:\n",
    "  - **`TensorFlow y Keras`**: Utilizadas para la implementación de modelos de redes neuronales.\n",
    "- **`Otras Bibliotecas`**:\n",
    "  - **`Pandas`**: Para el manejo de datos tabulares.\n",
    "  - **`Matplotlib`**: Utilizada para la visualización de datos y gráficos.\n",
    "  - **`PIL (Python Imaging Library)`**: Empleada para el procesamiento de imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## Configuración Inicial\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import noisereduce as nr\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf \n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.applications import EfficientNetB1\n",
    "from PIL import Image\n",
    "from sklearn.calibration import LabelEncoder\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del Conjunto de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Amazona Autamnails' 'Brotogeris pyrrhoptera' 'Campephilus gayaquilensis'\n",
      " 'Crypturellus tansfasciatus' 'Cyanocorax mystacalis' 'Euphonia saturata'\n",
      " 'Lathrotriccus griseipectus' 'Ortalis erythroptera'\n",
      " 'Pachyramphus spodiurus' 'Picumnus sclateri' 'Pseudastur occidentalis'\n",
      " 'Psittacara erythrogenys' 'Trogon mesurus']\n",
      "label\n",
      "Amazona Autamnails            650\n",
      "Psittacara erythrogenys       522\n",
      "Ortalis erythroptera          402\n",
      "Cyanocorax mystacalis         313\n",
      "Brotogeris pyrrhoptera        253\n",
      "Lathrotriccus griseipectus    244\n",
      "Campephilus gayaquilensis     187\n",
      "Crypturellus tansfasciatus    165\n",
      "Trogon mesurus                142\n",
      "Pseudastur occidentalis        96\n",
      "Picumnus sclateri              64\n",
      "Euphonia saturata              52\n",
      "Pachyramphus spodiurus         34\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ruta a la carpeta con los archivos de audio\n",
    "folder_path = \"./Dataset-Integradora-Bird/training/\"\n",
    "\n",
    "# Obtener la lista de archivos en la carpeta\n",
    "file_list = os.listdir(folder_path)\n",
    "# Filtrar la lista para obtener solo los archivos de audio\n",
    "audio_files = [file for file in file_list if file.endswith('.wav')]\n",
    "\n",
    "# Crear una lista de diccionarios con etiqueta y ruta\n",
    "data = []\n",
    "for audio_file in audio_files:\n",
    "    label, _ = audio_file.split('.', 1)\n",
    "    data.append({'label': label, 'path': os.path.join(folder_path, audio_file)})\n",
    "\n",
    "# Crear el DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "class_scientificnames = df['label'].unique()\n",
    "print(class_scientificnames)\n",
    "print(df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de Espectrogramas Mel y Creación de Imágenes\n",
    "La función `createSpectogramImageMel` se encarga de generar y guardar un espectrograma Mel a partir de una señal de audio dada. A continuación se presenta una explicación más detallada de cada paso dentro de esta función:\n",
    "\n",
    "1. **Configuración de parámetros de la transformada de Fourier de tiempo corto (STFT):**\n",
    "   - `n_fft`: Este parámetro define el tamaño de la ventana utilizada en la transformada de Fourier de tiempo corto (STFT). Especifica el número de muestras en cada ventana donde se realizará la STFT. En este caso, se utiliza una potencia de 2 para mejorar el rendimiento computacional.\n",
    "   - `hop_length`: Este parámetro determina la cantidad de muestras que se moverá la ventana en cada desplazamiento. Es decir, la cantidad de traslape entre ventanas adyacentes. Aquí, se establece en un cuarto de la longitud de la ventana (`n_fft`) para obtener un buen equilibrio entre resolución temporal y frecuencial.\n",
    "\n",
    "2. **Cálculo del espectrograma de magnitud:**\n",
    "   - Se utiliza la función `librosa.stft` para calcular la STFT de la señal de audio con los parámetros especificados. Luego, se calcula el valor absoluto de la STFT para obtener el espectrograma de magnitud.\n",
    "\n",
    "3. **Configuración de la ruta de guardado del espectrograma:**\n",
    "   - Se genera un nombre de archivo único para el espectrograma basado en la etiqueta de la clase y el hash de la señal de audio. Esto asegura que cada espectrograma tenga un nombre único.\n",
    "   - La ruta de guardado se configura combinando el directorio de guardado (`save_dir`) y el nombre de archivo generado.\n",
    "\n",
    "4. **Visualización y configuración del espectrograma:**\n",
    "   - Se crea una figura y un eje utilizando `plt.subplots()` para visualizar el espectrograma.\n",
    "   - Se normaliza el espectrograma utilizando la función `librosa.amplitude_to_db()` para convertir la magnitud de la STFT en decibelios (dB).\n",
    "   - Se utiliza `librosa.display.specshow()` para mostrar el espectrograma Mel en la figura.\n",
    "\n",
    "5. **Ajuste y eliminación de elementos no deseados:**\n",
    "   - Se eliminan títulos, etiquetas de ejes y barras de color para obtener una imagen limpia del espectrograma.\n",
    "   - Se ajusta el tamaño de la figura y se elimina el espacio en blanco alrededor de la imagen.\n",
    "\n",
    "6. **Guardado del espectrograma como archivo de imagen:**\n",
    "   - Se utiliza `plt.savefig()` para guardar la figura como un archivo de imagen en formato JPEG.\n",
    "   - La función crea el directorio de guardado si no existe y guarda la imagen en la ruta especificada.\n",
    "\n",
    "7. **Retorno de la ruta de la imagen guardada:**\n",
    "   - Se retorna la ruta completa del archivo de imagen recién guardado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSpectogramImageMel(signal, sr, label, save_dir=\"Dataset-Images-Mel\", img_size=(224, 224)):\n",
    "    n_fft = 2**11  # Nro. de muestras para cada ventana donde se va a realizar la stft\n",
    "    hop_length = int(n_fft/4)  # Cuántas muestras se va a mover la ventana en cada desplazamiento (hop: salto)\n",
    "    stft = librosa.stft(signal, n_fft=n_fft, hop_length=hop_length, win_length=None, window='hann')\n",
    "    spectrogram_magnitude = np.abs(stft)\n",
    "    \n",
    "    # Configurar la ruta de guardado\n",
    "    filename = f\"{label}_{hashlib.sha1(signal.tobytes()).hexdigest()[:8]}_{len(os.listdir(save_dir))}.jpeg\"\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "\n",
    "    # Visualizar el espectrograma normalizado sin valores de frecuencia\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(img_size[0]/100, img_size[1]/100))  # Ajustar el tamaño de la figura\n",
    "    fig.patch.set_facecolor('white')\n",
    "    spectrogram_dB = librosa.amplitude_to_db(spectrogram_magnitude, ref=np.max)\n",
    "    librosa.display.specshow(spectrogram_dB, y_axis='mel', fmin=0, fmax=sr/2, x_axis='time', sr=sr, hop_length=hop_length)\n",
    "\n",
    "    # Eliminar títulos y etiquetas\n",
    "    ax.set_title('')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "\n",
    "    plt.colorbar(format='%+2.0f dB').remove()\n",
    "\n",
    "    # Eliminar etiquetas de ejes x e y\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Ajustar el tamaño de la imagen al guardarla\n",
    "    fig.tight_layout(pad=0)\n",
    "\n",
    "    # Guardar la figura en el archivo de imagen con el tamaño especificado\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    plt.savefig(save_path, bbox_inches=\"tight\", pad_inches=0, dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas con Datos Aleatorios y Visualización de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar una muestra aleatoria del conjunto de datos\n",
    "import IPython\n",
    "\n",
    "random_data = df.sample()\n",
    "random_path = random_data['path'].values[0]  # Acceder al valor de la primera fila\n",
    "random_label = random_data['label'].values[0]  # Acceder al valor de la primera fila\n",
    "\n",
    "# Mostrar la ruta aleatoria seleccionada y la etiqueta correspondiente\n",
    "print(\"Ruta aleatoria:\", random_path)\n",
    "print(\"Etiqueta aleatoria:\", random_label)\n",
    "\n",
    "# Cargar la señal de audio desde la ruta aleatoria seleccionada\n",
    "signal, sr = librosa.load(random_path, sr=None)  # sr = sampling rate\n",
    "\n",
    "# Visualizar la señal de audio como un archivo de audio interactivo\n",
    "IPython.display.Audio(signal, rate=sr)\n",
    "\n",
    "# Generar el espectrograma Mel correspondiente a la señal de audio y guardar la imagen\n",
    "image_path = createSpectogramImageMel(signal=signal, sr=sr, label=random_label)\n",
    "\n",
    "# Imprimir la ruta de la imagen guardada\n",
    "print(\"Ruta de la imagen del espectrograma:\", image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de Datos de Entrenamiento Adicionales\n",
    "1. **Inicialización de `data_training`:**\n",
    "   - La variable `data_training` se inicializa como una lista vacía. Este será el contenedor donde almacenaremos los datos de entrenamiento adicionales que generaremos.\n",
    "\n",
    "2. **Iteración sobre el DataFrame original (`df`):**\n",
    "   - Utilizamos un bucle `for` junto con `df.iterrows()` para iterar sobre cada fila del DataFrame original `df`. Cada fila representa un archivo de audio y su correspondiente etiqueta.\n",
    "\n",
    "3. **Procesamiento de cada muestra de audio:**\n",
    "   - Para cada fila del DataFrame, extraemos la ruta del archivo de audio (`path`) y su etiqueta (`label`).\n",
    "   - Cargamos la señal de audio utilizando la función `librosa.load()`, especificando `sr=None` para mantener la frecuencia de muestreo original.\n",
    "   - Aplicamos la reducción de ruido a la señal de audio utilizando `nr.reduce_noise()` de la librería `noisereduce`.\n",
    "   \n",
    "4. **Generación de datos adicionales para ciertas clases:**\n",
    "   - Verificamos si la etiqueta no está en una lista específica de nombres de clases. Si no está en esa lista, generamos variaciones de la señal de audio y creamos espectrogramas Mel para cada variación.\n",
    "   - Las variaciones incluyen desplazamientos de tono (`y_roll` y `y_pitch2`) y una reducción de la amplitud (`y_scaled`).\n",
    "   - Para cada variación, creamos un espectrograma Mel correspondiente utilizando la función `createSpectogramImageMel()` y guardamos la ruta del archivo de imagen junto con su etiqueta en la lista `data_training`.\n",
    "   \n",
    "5. **Procesamiento adicional para clases específicas:**\n",
    "   - Si la etiqueta está en una lista específica de nombres de clases, generamos una variación adicional de la señal de audio (`y_pitch3`) y creamos un espectrograma Mel correspondiente.\n",
    "   \n",
    "6. **Creación del DataFrame `datframe`:**\n",
    "   - Una vez que hemos generado todas las muestras de entrenamiento adicionales, creamos un nuevo DataFrame llamado `datframe` a partir de la lista `data_training`.\n",
    "\n",
    "7. **Impresión de la distribución de etiquetas:**\n",
    "   - Finalmente, imprimimos la distribución de las etiquetas en el conjunto de datos de entrenamiento utilizando `datframe[1].value_counts()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training = []\n",
    "\n",
    "# Iterar sobre cada fila del DataFrame original\n",
    "for index, row in df.iterrows():\n",
    "    path = row[\"path\"]\n",
    "    label = row[\"label\"]\n",
    "    signal, sr = librosa.load(path, sr=None)  # sr = sampling rate\n",
    "    signal = nr.reduce_noise(y=signal, y_noise=signal, prop_decrease=1, sr=sr)\n",
    "\n",
    "    # Generar datos adicionales solo para ciertas clases\n",
    "    if label not in [\"Amazona Autamnails\", \"Psittacara erythrogenys\", \"Ortalis erythroptera\", \"Cyanocorax mystacalis\", \"Brotogeris pyrrhoptera\", \"Lathrotriccus griseipectus\"]:\n",
    "        # Manipulación de la señal de audio para generar variaciones\n",
    "        y_roll = np.roll(signal, 7000)\n",
    "        y_pitch2 = np.roll(signal, 30000)\n",
    "        y_scaled = 0.6 * signal  # Reducir la amplitud en un 40%\n",
    "\n",
    "        # Crear espectrogramas Mel para las variaciones de la señal\n",
    "        pitchspectogram2_path = createSpectogramImageMel(signal=y_pitch2, sr=sr, label=label)\n",
    "        pitchspectogram_path = createSpectogramImageMel(signal=y_roll, sr=sr, label=label)\n",
    "        scaledspectogram_path = createSpectogramImageMel(signal=y_scaled, sr=sr, label=label)\n",
    "        spectogram_path = createSpectogramImageMel(signal=signal, sr=sr, label=label)\n",
    "\n",
    "        # Agregar las rutas de los espectrogramas y las etiquetas al conjunto de datos\n",
    "        data_training.append([pitchspectogram2_path, label])\n",
    "        data_training.append([spectogram_path, label])\n",
    "        data_training.append([pitchspectogram_path, label])\n",
    "        data_training.append([scaledspectogram_path, label])\n",
    "\n",
    "    else:\n",
    "        # Generar espectrogramas Mel para las señales de audio sin manipulación adicional\n",
    "        spectogram_path = createSpectogramImageMel(signal=signal, sr=sr, label=label)\n",
    "        data_training.append([spectogram_path, label])\n",
    "\n",
    "    # Generar datos adicionales solo para ciertas clases\n",
    "    if label in [\"Pseudastur occidentalis\",\"Picumnus sclateri\",\"Euphonia saturata\",\"Pachyramphus spodiurus\"]:\n",
    "        y_pitch3 = np.roll(signal, 80000)  \n",
    "        pitchspectogram_path = createSpectogramImageMel(signal=y_pitch3, sr=sr, label=label)\n",
    "        data_training.append([pitchspectogram_path, label])\n",
    "\n",
    "# Crear un DataFrame con los datos de entrenamiento adicionales generados\n",
    "datframe = pd.DataFrame(data_training)\n",
    "\n",
    "# Imprimir la distribución de las etiquetas en el conjunto de datos de entrenamiento\n",
    "print(datframe[1].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
